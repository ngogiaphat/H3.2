{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "nodes = 256\n",
    "embed_size = 20\n",
    "\n",
    "# Tensor where we will feed the data into graph\n",
    "inputs = tf.placeholder(tf.float32, (None, x_seq_length, nxchars), 'inputs')\n",
    "outputs = tf.placeholder(tf.int32, (None, None), 'output')\n",
    "targets = tf.placeholder(tf.int32, (None, None), 'targets')\n",
    "\n",
    "# Embedding layers\n",
    "output_embedding = tf.Variable(tf.random_uniform((len(ltokens)+1, embed_size), -1.0, 1.0), name='dec_embedding')\n",
    "date_output_embed = tf.nn.embedding_lookup(output_embedding, outputs)\n",
    "\n",
    "with tf.variable_scope(\"encoding\") as encoding_scope:\n",
    "    lstm_enc = tf.contrib.rnn.BasicLSTMCell(nodes)\n",
    "    _, last_state = tf.nn.dynamic_rnn(lstm_enc, inputs=inputs, dtype=tf.float32)\n",
    "\n",
    "with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "    lstm_dec = tf.contrib.rnn.BasicLSTMCell(nodes)\n",
    "    dec_outputs, _ = tf.nn.dynamic_rnn(lstm_dec, inputs=date_output_embed, initial_state=last_state)\n",
    "#connect outputs to \n",
    "logits = tf.contrib.layers.fully_connected(dec_outputs, num_outputs=len(ltokens)+1, activation_fn=None) \n",
    "with tf.name_scope(\"optimization\"):\n",
    "    # Loss function\n",
    "    loss = tf.contrib.seq2seq.sequence_loss(logits, targets, tf.ones([batch_size, y_seq_length]))\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.RMSPropOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    restore(sess)\n",
    "    epochs = 1000\n",
    "    for epoch_i in range(epochs):\n",
    "        start_time = time.time()\n",
    "        for batch_i, (source_batch, target_batch) in enumerate(batch_data(X_train, y_train, batch_size)):\n",
    "            _, batch_loss, batch_logits = sess.run([optimizer, loss, logits],\n",
    "                feed_dict = {inputs: source_batch,\n",
    "                 outputs: target_batch[:, :-1],\n",
    "                 targets: target_batch[:, 1:]})\n",
    "\n",
    "        accuracy = np.mean(batch_logits.argmax(axis=-1) == target_batch[:,1:])\n",
    "        print('Epoch {:3} Loss: {:>6.3f} Accuracy: {:>6.4f} Epoch duration: {:>6.3f}s'.format(epoch_i, batch_loss, \n",
    "                                                                          accuracy, time.time() - start_time))\n",
    "\n",
    "        source_batch, target_batch = next(batch_data(X_test, y_test, batch_size))\n",
    "\n",
    "        dec_input = np.zeros((len(source_batch), 1)) + len(ltokens)\n",
    "        for i in range(y_seq_length):\n",
    "            batch_logits = sess.run(logits,\n",
    "                        feed_dict = {inputs: source_batch,\n",
    "                         outputs: dec_input})\n",
    "            prediction = batch_logits[:,-1].argmax(axis=-1)\n",
    "            dec_input = np.hstack([dec_input, prediction[:,None]])\n",
    "\n",
    "        print('Accuracy on test set is: {:>6.3f}'.format(np.mean(dec_input == target_batch)))     \n",
    "        if epoch_i % 5 == 0:\n",
    "            save(sess)\n",
    "    \n",
    "    save(sess)\n",
    "    with tf.Session() as sess: \n",
    "    restore(sess)\n",
    "    batch_size = 512\n",
    "    source_batch, target_batch = next(batch_data(X_test, y_test, batch_size))\n",
    "\n",
    "    dec_input = np.zeros((len(source_batch), 1)) + len(ltokens)\n",
    "    for i in range(y_seq_length):\n",
    "        batch_logits = sess.run(logits,\n",
    "                    feed_dict = {inputs: source_batch,\n",
    "                     outputs: dec_input})\n",
    "        prediction = batch_logits[:,-1].argmax(axis=-1)\n",
    "        dec_input = np.hstack([dec_input, prediction[:,None]])\n",
    "\n",
    "    print('Accuracy on test set is: {:>6.3f}'.format(np.mean(dec_input == target_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = random.randint(0, 511)\n",
    "print(dec_input[i,:])\n",
    "print(ltokens)\n",
    "seq = \"\"\n",
    "for c in dec_input[i,1:]:\n",
    "    c = int(c)\n",
    "    if c != 28:\n",
    "        seq += ltokens[c] \n",
    "        \n",
    "print(\"result:\", seq)\n",
    "\n",
    "seq = \"\"\n",
    "for c in target_batch[i,1:]:\n",
    "    c = int(c)\n",
    "    \n",
    "    if c != 28:\n",
    "        seq += ltokens[c] \n",
    "\n",
    "print(\"Correct:\", seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess: \n",
    "    restore(sess)\n",
    "    batch_size = 512\n",
    "    source_batch, target_batch = next(batch_data(X_test, y_test, batch_size))\n",
    "\n",
    "    dec_input = np.zeros((len(source_batch), 1)) + len(ltokens)\n",
    "    for i in range(y_seq_length):\n",
    "        batch_logits = sess.run(logits,\n",
    "                    feed_dict = {inputs: source_batch,\n",
    "                     outputs: dec_input})\n",
    "        prediction = batch_logits[:,-1].argmax(axis=-1)\n",
    "        dec_input = np.hstack([dec_input, prediction[:,None]])\n",
    "\n",
    "    print('Accuracy on test set is: {:>6.3f}'.format(np.mean(dec_input == target_batch)))\n",
    "    cc = 0\n",
    "    fcc = 0\n",
    "    fc = 0\n",
    "    fl = 0\n",
    "    nl = 0\n",
    "    for i in range(len(dec_input)):\n",
    "        feq = False\n",
    "        pseq = \"\"\n",
    "        for c in dec_input[i,1:]:\n",
    "            c = int(c)\n",
    "            if c != 28:\n",
    "                pseq += ltokens[c] \n",
    "\n",
    "        cseq = \"\"\n",
    "        cseql = \"\"\n",
    "        for c in target_batch[i,1:]:\n",
    "            c = int(c)\n",
    "\n",
    "            if c != 28:\n",
    "                cseq += ltokens[c] \n",
    "                cseql += ltokens[c][0]\n",
    "                if ltokens[c] == \"#frac\":\n",
    "                    fc += 1\n",
    "                    feq = True\n",
    "\n",
    "        if pseq == cseq:\n",
    "            cc += 1\n",
    "            if feq:\n",
    "                fcc += 1\n",
    "        cseql = cseql.rstrip()\n",
    "        if feq:\n",
    "            fl += len(cseql)\n",
    "        else:\n",
    "            nl += len(cseql)\n",
    "        \n",
    "    print(\"Accuracy %.2f %%\" % (cc/len(dec_input)*100))  \n",
    "    print(\"Accuracy for fraction equations %.2f %%\" % (fcc/fc*100))\n",
    "    print(\"Accuracy for simple equations %.2f %%\" % ((cc-fcc)/(len(dec_input)-fc)*100))\n",
    "    print(\"Average length frac: %.1f\" % (fl/fc))\n",
    "    print(\"Average length simple: %.1f\" % (nl/(len(dec_input)-fc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f89a6901c0898be621f5bef48f4a38883fc81d86ed5883daf9e30a1fc7fc3d5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
